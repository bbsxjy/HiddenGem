# HiddenGem åç«¯æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å·²å®ç°çš„6é¡¹æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½ï¼Œä»¥åŠå¦‚ä½•é…ç½®å’Œä½¿ç”¨å®ƒä»¬ã€‚

## ğŸ“Š ä¼˜åŒ–æ¦‚è§ˆ

| ä¼˜åŒ–é¡¹ | é¢„æœŸæ•ˆæœ | çŠ¶æ€ |
|--------|---------|------|
| TTLç¼“å­˜ | å‡å°‘60-80% APIè¯·æ±‚ | âœ… å·²å®ç° |
| LLMåˆ†å±‚è·¯ç”± | é™ä½30-50% LLMæˆæœ¬ | âœ… å·²å®ç° |
| Prometheusç›‘æ§ | å®æ—¶æ€§èƒ½ç›‘æ§ | âœ… å·²å®ç° |
| JSONLè®­ç»ƒæ•°æ®å¯¼å‡º | æ”¯æŒå°æ¨¡å‹å¾®è°ƒ | âœ… å·²å®ç° |
| LLMä¸Šä¸‹æ–‡è£å‰ª | å‡å°‘30-50% Tokenæ¶ˆè€— | âœ… å·²å®ç° |
| LLMç»“æœç¼“å­˜ | å‡å°‘40-60% APIè°ƒç”¨ | âœ… å·²å®ç° |

---

## 1. TTLç¼“å­˜ç³»ç»Ÿ

### åŠŸèƒ½è¯´æ˜

ä¸‰å±‚ç¼“å­˜æ¶æ„ï¼Œè‡ªåŠ¨ç¼“å­˜æ•°æ®è¯·æ±‚ç»“æœï¼š
- **L1**: TTLCache (å†…å­˜ï¼Œå¿«é€Ÿè®¿é—®)
- **L2**: DiskCache (ç£ç›˜ï¼ŒæŒä¹…åŒ–)
- **L3**: Redis (å¯é€‰ï¼Œåˆ†å¸ƒå¼)

### å·²åº”ç”¨ä½ç½®

ä»¥ä¸‹å‡½æ•°å·²è‡ªåŠ¨å¯ç”¨TTLç¼“å­˜ï¼ˆé»˜è®¤1å°æ—¶ï¼‰ï¼š

```python
# tradingagents/dataflows/data_source_manager.py
@ttl_cache(ttl=3600)
def _get_tushare_data(symbol, start_date, end_date)

@ttl_cache(ttl=3600)
def _get_akshare_data(symbol, start_date, end_date)

@ttl_cache(ttl=3600)
def get_china_stock_data_unified(symbol, start_date, end_date)
```

### ä½¿ç”¨æ–¹æ³•

#### æ–¹æ³•1: ä½¿ç”¨è£…é¥°å™¨ï¼ˆæ¨èï¼‰

```python
from tradingagents.dataflows.ttl_cache import ttl_cache

@ttl_cache(ttl=3600)  # ç¼“å­˜1å°æ—¶
def my_expensive_function(param1, param2):
    # æ‰§è¡Œè€—æ—¶æ“ä½œ
    return result
```

#### æ–¹æ³•2: æ‰‹åŠ¨ç¼“å­˜

```python
from tradingagents.dataflows.ttl_cache import get_hybrid_cache

cache = get_hybrid_cache()

# å­˜å‚¨
cache.set("my_key", {"data": "value"}, ttl=3600)

# è¯»å–
result = cache.get("my_key")
if result is None:
    result = fetch_data()
    cache.set("my_key", result, ttl=3600)
```

### é…ç½®å‚æ•°

```python
# .env æ–‡ä»¶
CACHE_DIR=.cache              # ç£ç›˜ç¼“å­˜ç›®å½•
CACHE_MAX_SIZE=1000000000     # æœ€å¤§ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼Œé»˜è®¤1GBï¼‰
REDIS_URL=redis://localhost:6379/0  # Redis URLï¼ˆå¯é€‰ï¼‰
```

### æ€§èƒ½æå‡

- **é¦–æ¬¡è¯·æ±‚**: æ­£å¸¸é€Ÿåº¦ï¼ˆéœ€è¦å®é™…APIè°ƒç”¨ï¼‰
- **ç¼“å­˜å‘½ä¸­**: é€Ÿåº¦æå‡100-1000å€ï¼ˆå–å†³äºAPIå»¶è¿Ÿï¼‰
- **ç¼“å­˜å‘½ä¸­ç‡**: é€šå¸¸60-80%ï¼ˆå–å†³äºäº¤æ˜“é¢‘ç‡ï¼‰

---

## 2. LLMåˆ†å±‚è·¯ç”±ç³»ç»Ÿ

### åŠŸèƒ½è¯´æ˜

æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„LLMæ¨¡å‹ï¼š
- **SMALL**: ç®€å•ä»»åŠ¡ï¼ˆå¦‚Traderæ‰§è¡Œä¿¡å·ï¼‰
- **MEDIUM**: å¸¸è§„åˆ†æï¼ˆå¦‚å¸‚åœº/åŸºæœ¬é¢åˆ†æï¼‰
- **LARGE**: å¤æ‚æ¨ç†ï¼ˆå¦‚è¾©è®ºè£åˆ¤/é£é™©å†³ç­–ï¼‰

### é…ç½®æ–¹æ³•

#### æ­¥éª¤1: è®¾ç½®ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
SMALL_LLM=qwen-turbo                    # å°æ¨¡å‹ï¼ˆå¿«é€Ÿ+ä¾¿å®œï¼‰
QUICK_THINK_LLM=qwen-plus               # ä¸­ç­‰æ¨¡å‹ï¼ˆå¹³è¡¡ï¼‰
DEEP_THINK_LLM=qwen-max                 # å¤§æ¨¡å‹ï¼ˆå¤æ‚æ¨ç†ï¼‰
ENABLE_SMALL_MODEL_ROUTING=true         # å¯ç”¨åˆ†å±‚è·¯ç”±
```

#### æ­¥éª¤2: åˆå§‹åŒ–è·¯ç”±å™¨

```python
from tradingagents.utils.llm_router import get_llm_router

router = get_llm_router()

# è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
llm = router.get_llm_for_agent("market")  # è¿”å› MEDIUM æ¨¡å‹
llm = router.get_llm_for_agent("trader")  # è¿”å› SMALL æ¨¡å‹
llm = router.get_llm_for_agent("research_manager")  # è¿”å› LARGE æ¨¡å‹
```

### Agentå¤æ‚åº¦æ˜ å°„

| Agentç±»å‹ | å¤æ‚åº¦ | ä½¿ç”¨æ¨¡å‹ | è¯´æ˜ |
|-----------|--------|----------|------|
| trader | SIMPLE | SMALL | æ‰§è¡Œç®€å•ä¿¡å· |
| market | ROUTINE | MEDIUM | å¸‚åœºåˆ†æ |
| fundamentals | ROUTINE | MEDIUM | åŸºæœ¬é¢åˆ†æ |
| sentiment | ROUTINE | MEDIUM | æƒ…ç»ªåˆ†æ |
| news | ROUTINE | MEDIUM | æ–°é—»åˆ†æ |
| research_manager | COMPLEX | LARGE | è¾©è®ºè£åˆ¤ |
| risk_manager | COMPLEX | LARGE | é£é™©å†³ç­– |

### æ¨èæ¨¡å‹ç»„åˆ

#### é¢„ç®—ä¼˜å…ˆï¼ˆQwenç³»åˆ—ï¼‰

```bash
SMALL_LLM=qwen-turbo        # Â¥0.002/1K tokens
QUICK_THINK_LLM=qwen-plus   # Â¥0.004/1K tokens
DEEP_THINK_LLM=qwen-max     # Â¥0.04/1K tokens
```

#### æ€§èƒ½ä¼˜å…ˆï¼ˆDeepSeekç³»åˆ—ï¼‰

```bash
SMALL_LLM=deepseek-chat     # Â¥0.001/1K tokens
QUICK_THINK_LLM=deepseek-chat # Â¥0.001/1K tokens
DEEP_THINK_LLM=deepseek-reasoner # Â¥0.014/1K tokens
```

#### è´¨é‡ä¼˜å…ˆï¼ˆOpenAIç³»åˆ—ï¼‰

```bash
SMALL_LLM=gpt-4o-mini       # $0.15/1M tokens
QUICK_THINK_LLM=gpt-4o      # $2.50/1M tokens
DEEP_THINK_LLM=o1-mini      # $3.00/1M tokens
```

### æˆæœ¬å¯¹æ¯”

å‡è®¾å•æ¬¡å®Œæ•´åˆ†æï¼ˆ7ä¸ªAgentï¼‰æ¶ˆè€—çº¦50K tokensï¼š

| é…ç½® | å•æ¬¡æˆæœ¬ | 1000æ¬¡æˆæœ¬ |
|------|---------|-----------|
| å…¨éƒ¨ä½¿ç”¨å¤§æ¨¡å‹ | Â¥2.00 | Â¥2000 |
| å¯ç”¨åˆ†å±‚è·¯ç”± | Â¥0.80 | Â¥800 |
| **èŠ‚çœ** | **Â¥1.20** | **Â¥1200 (60%)** |

---

## 3. Prometheusç›‘æ§ç³»ç»Ÿ

### åŠŸèƒ½è¯´æ˜

æä¾›ç³»ç»Ÿçº§ç›‘æ§æŒ‡æ ‡ï¼š
- ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ˆå¿ƒè·³ã€é‡å¯æ¬¡æ•°ï¼‰
- ç¼“å­˜æ€§èƒ½ï¼ˆå‘½ä¸­ç‡ã€è¯·æ±‚æ•°ï¼‰
- APIè°ƒç”¨ç»Ÿè®¡ï¼ˆæˆåŠŸç‡ã€å»¶è¿Ÿï¼‰
- LLMä½¿ç”¨ç»Ÿè®¡ï¼ˆTokenæ¶ˆè€—ã€æˆæœ¬ï¼‰
- ä»»åŠ¡è¿›åº¦ï¼ˆTime Travelè®­ç»ƒè¿›åº¦ï¼‰

### APIç«¯ç‚¹

```bash
# JSONæ ¼å¼æŒ‡æ ‡
GET http://localhost:8000/api/v1/metrics

# Prometheusæ–‡æœ¬æ ¼å¼
GET http://localhost:8000/api/v1/metrics/prometheus

# å¥åº·æ£€æŸ¥ï¼ˆKubernetesæ¢é’ˆï¼‰
GET http://localhost:8000/api/v1/health

# ç®€åŒ–æ‘˜è¦
GET http://localhost:8000/api/v1/metrics/summary
```

### å“åº”ç¤ºä¾‹

#### JSONæ ¼å¼

```json
{
  "success": true,
  "data": {
    "timestamp": "2025-01-15T10:30:00",
    "system_health": {
      "heartbeat_seconds": 15.2,
      "restart_count": 0,
      "is_healthy": true
    },
    "cache_performance": {
      "hits": 1234,
      "misses": 456,
      "total": 1690,
      "hit_rate": 0.73
    },
    "api_statistics": {
      "total_requests": 5678,
      "successful_requests": 5520,
      "failed_requests": 158,
      "success_rate": 0.97,
      "duration_stats": {
        "count": 5678,
        "avg": 0.85,
        "min": 0.12,
        "max": 3.45
      }
    },
    "llm_usage": {
      "total_tokens": 1234567,
      "total_cost_yuan": 123.45,
      "requests_by_tier": {
        "small": 1000,
        "medium": 500,
        "large": 100
      }
    }
  }
}
```

#### Prometheusæ ¼å¼

```
# HELP auto_trading_heartbeat_seconds Seconds since last heartbeat
# TYPE auto_trading_heartbeat_seconds gauge
auto_trading_heartbeat_seconds 15.2

# HELP data_cache_hits_total Total number of cache hits
# TYPE data_cache_hits_total counter
data_cache_hits_total 1234

# HELP data_cache_hit_rate Cache hit rate
# TYPE data_cache_hit_rate gauge
data_cache_hit_rate 0.73
```

### é›†æˆPrometheus

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'hiddengem-backend'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/api/v1/metrics/prometheus'
```

### é›†æˆGrafana

å¯¼å…¥ä»ªè¡¨æ¿æ¨¡æ¿ï¼ˆå¾…åˆ›å»ºï¼‰æˆ–æ‰‹åŠ¨åˆ›å»ºé¢æ¿ï¼š

```promql
# ç¼“å­˜å‘½ä¸­ç‡
data_cache_hit_rate

# APIæˆåŠŸç‡
rate(api_requests_success_total[5m]) / rate(api_requests_total[5m])

# LLMæˆæœ¬è¶‹åŠ¿
rate(llm_cost_total_yuan[1h])
```

### ç¨‹åºå†…ä½¿ç”¨

```python
from tradingagents.utils.monitoring_metrics import get_metrics_collector

metrics = get_metrics_collector()

# è®°å½•ç¼“å­˜å‘½ä¸­
metrics.record_cache_hit()

# è®°å½•APIè¯·æ±‚
metrics.record_api_request(success=True, duration=0.5)

# è®°å½•LLMä½¿ç”¨
metrics.record_llm_usage(tokens=1000, cost=0.04, tier="medium")

# è·å–æŒ‡æ ‡
current_metrics = metrics.get_metrics()
print(f"ç¼“å­˜å‘½ä¸­ç‡: {current_metrics['cache_performance']['hit_rate']:.2%}")
```

---

## 4. JSONLè®­ç»ƒæ•°æ®å¯¼å‡º

### åŠŸèƒ½è¯´æ˜

Time Travelè®­ç»ƒè„šæœ¬ç°åœ¨ä¼šè‡ªåŠ¨å¯¼å‡ºJSONLæ ¼å¼è®­ç»ƒæ•°æ®ï¼Œç”¨äºï¼š
- å°æ¨¡å‹SFTï¼ˆSupervised Fine-Tuningï¼‰
- LoRAå¾®è°ƒ
- Knowledge Distillation
- Prompt Engineeringï¼ˆfew-shotç¤ºä¾‹ï¼‰

### æ•°æ®æ ¼å¼

```json
{
  "instruction": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚æ ¹æ®å¸‚åœºæ•°æ®å’Œå„ä¸ªåˆ†æå¸ˆçš„æŠ¥å‘Šï¼Œåšå‡ºåˆç†çš„äº¤æ˜“å†³ç­–...",
  "input": "## å¸‚åœºçŠ¶æ€\n- æ—¥æœŸ: 2024-01-15\n- è‚¡ç¥¨: 000001.SZ\n- å½“å‰ä»·æ ¼: Â¥15.23\n\n## åˆ†æå¸ˆæŠ¥å‘Š\n### MARKET Analyst\næŠ€æœ¯é¢åˆ†ææ˜¾ç¤º...\n\n### FUNDAMENTALS Analyst\nåŸºæœ¬é¢ç¨³å¥...",
  "output": "## æŠ•èµ„è¾©è®ºç»“è®º\nç»¼åˆå¤šç©ºè§‚ç‚¹...\n\n## æœ€ç»ˆå†³ç­–\nä¹°å…¥\n\n## å†³ç­–ä¾æ®\nåŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘çš„å†³ç­–æ˜¯ï¼šä¹°å…¥\nå…¥åœºä»·æ ¼ï¼šÂ¥15.23\nç›®æ ‡æŒä»“å¤©æ•°ï¼š5å¤©",
  "metadata": {
    "date": "2024-01-15",
    "symbol": "000001.SZ",
    "action": "buy",
    "success": true,
    "percentage_return": 0.0523,
    "holding_days": 5,
    "entry_price": 15.23,
    "exit_price": 16.03
  }
}
```

### ä½¿ç”¨æ–¹æ³•

#### è¿è¡ŒTime Travelè®­ç»ƒ

```bash
python scripts/enhanced_time_travel_training.py \
    --symbol 000001.SZ \
    --start 2024-01-01 \
    --end 2024-12-31 \
    --holding-days 5
```

#### è¾“å‡ºæ–‡ä»¶

```
training_data/
â”œâ”€â”€ sft_training_data_000001_SZ_20250115_143022.jsonl  # è®­ç»ƒæ•°æ®
â””â”€â”€ sft_metadata_000001_SZ_20250115_143022.json        # å…ƒæ•°æ®æ‘˜è¦
```

#### å…ƒæ•°æ®æ‘˜è¦ç¤ºä¾‹

```json
{
  "symbol": "000001.SZ",
  "start_date": "2024-01-01",
  "end_date": "2024-12-31",
  "total_episodes": 200,
  "successful_episodes": 145,
  "failed_episodes": 55,
  "action_distribution": {
    "buy": 80,
    "sell": 40,
    "hold": 80
  },
  "export_timestamp": "2025-01-15T14:30:22",
  "jsonl_file": "training_data/sft_training_data_000001_SZ_20250115_143022.jsonl"
}
```

### è®­ç»ƒå°æ¨¡å‹

#### ä½¿ç”¨LLaMA-Factory

```bash
# 1. å®‰è£…LLaMA-Factory
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -r requirements.txt

# 2. å‡†å¤‡æ•°æ®é›†é…ç½®
cat > data/dataset_info.json <<EOF
{
  "hiddengem_trading": {
    "file_name": "path/to/sft_training_data_000001_SZ_20250115_143022.jsonl",
    "formatting": "alpaca",
    "columns": {
      "prompt": "instruction",
      "query": "input",
      "response": "output"
    }
  }
}
EOF

# 3. å¯åŠ¨LoRAå¾®è°ƒ
llamafactory-cli train \
    --model_name_or_path Qwen/Qwen2.5-7B-Instruct \
    --dataset hiddengem_trading \
    --output_dir output/qwen_trading_lora \
    --finetuning_type lora \
    --lora_rank 8 \
    --learning_rate 5e-5 \
    --num_train_epochs 3 \
    --per_device_train_batch_size 4
```

#### ä½¿ç”¨Hugging Face Transformers

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer
from datasets import load_dataset

# åŠ è½½JSONLæ•°æ®
dataset = load_dataset('json', data_files='sft_training_data_000001_SZ_20250115_143022.jsonl')

# åŠ è½½åŸºç¡€æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B-Instruct")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

# æ•°æ®é¢„å¤„ç†
def format_example(example):
    text = f"{example['instruction']}\n\n{example['input']}\n\n{example['output']}"
    return tokenizer(text, truncation=True, max_length=2048)

dataset = dataset.map(format_example)

# è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./qwen_trading",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    learning_rate=5e-5,
    logging_steps=10,
    save_steps=100
)

# å¼€å§‹è®­ç»ƒ
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train']
)
trainer.train()
```

---

## 5. LLMä¸Šä¸‹æ–‡è£å‰ª

### åŠŸèƒ½è¯´æ˜

æ™ºèƒ½æˆªæ–­è¿‡é•¿è¾“å…¥ï¼Œå‡å°‘Tokenæ¶ˆè€—ï¼š
- **tail**: åªä¿ç•™å¼€å¤´
- **middle**: ä¿ç•™å¼€å¤´+ç»“å°¾
- **smart**: ä¿ç•™ç« èŠ‚æ ‡é¢˜

### ä½¿ç”¨æ–¹æ³•

#### æ–¹æ³•1: ä½¿ç”¨è£…é¥°å™¨ï¼ˆè‡ªåŠ¨ï¼‰

```python
from tradingagents.utils.llm_optimization import optimize_llm_call

@optimize_llm_call(
    enable_pruning=True,
    max_tokens=4000,
    truncate_strategy="middle"
)
def call_llm(prompt: str, model: str) -> str:
    # è‡ªåŠ¨è£å‰ªpromptï¼ˆå¦‚æœè¶…è¿‡4000 tokensï¼‰
    response = llm.invoke(prompt)
    return response
```

#### æ–¹æ³•2: æ‰‹åŠ¨è£å‰ª

```python
from tradingagents.utils.llm_optimization import prune_context

long_text = """
# éå¸¸é•¿çš„å¸‚åœºæŠ¥å‘Š...
ï¼ˆå‡è®¾10000ä¸ªtokenï¼‰
"""

# è£å‰ªä¸º4000 tokens
pruned = prune_context(long_text, max_tokens=4000, strategy="middle")

# ä½¿ç”¨è£å‰ªåçš„æ–‡æœ¬
response = llm.invoke(pruned)
```

### è£å‰ªç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | ä¿ç•™å†…å®¹ | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|
| tail | ä»…å¼€å¤´ | ç»“è®ºåœ¨å‰çš„æŠ¥å‘Š |
| middle | å¼€å¤´+ç»“å°¾ | æ‘˜è¦åœ¨å‰åçš„æ–‡æ¡£ |
| smart | æ ‡é¢˜+éƒ¨åˆ†å†…å®¹ | ç»“æ„åŒ–Markdownæ–‡æ¡£ |

### Tokenä¼°ç®—è§„åˆ™

```python
# ä¸­æ–‡ï¼š1å­— â‰ˆ 1 token
"å¹³å®‰é“¶è¡Œ" â†’ 4 tokens

# è‹±æ–‡ï¼š4å­—ç¬¦ â‰ˆ 1 token
"Apple Inc." â†’ 2.5 tokens

# æ··åˆæ–‡æœ¬
"å¹³å®‰é“¶è¡Œ (Ping An Bank)" â†’ 4 + 4 = 8 tokens
```

### æ•ˆæœç¤ºä¾‹

```python
# åŸå§‹promptï¼ˆä¼°ç®—10000 tokensï¼‰
prompt = """
è¯·åˆ†æä»¥ä¸‹å¸‚åœºæŠ¥å‘Šï¼š

# å¸‚åœºæ¦‚å†µ
ä»Šæ—¥Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“æ”¶è·Œ...ï¼ˆéå¸¸è¯¦ç»†çš„æè¿°ï¼Œ5000å­—ï¼‰

# è¡Œä¸šæ¿å—
é“¶è¡Œæ¿å—è¡¨ç°å¼ºåŠ¿...ï¼ˆéå¸¸è¯¦ç»†çš„æè¿°ï¼Œ3000å­—ï¼‰

# ä¸ªè‚¡åˆ†æ
å¹³å®‰é“¶è¡Œ(000001.SZ)...ï¼ˆéå¸¸è¯¦ç»†çš„æè¿°ï¼Œ2000å­—ï¼‰
"""

# è£å‰ªåï¼ˆ4000 tokensï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼‰
pruned = prune_context(prompt, max_tokens=4000, strategy="middle")

# ç»“æœï¼š
"""
è¯·åˆ†æä»¥ä¸‹å¸‚åœºæŠ¥å‘Šï¼š

# å¸‚åœºæ¦‚å†µ
ä»Šæ—¥Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“æ”¶è·Œ...ï¼ˆä¿ç•™å¼€å¤´80%ï¼‰

...[ä¸­é—´å†…å®¹å·²æˆªæ–­]...

# ä¸ªè‚¡åˆ†æ
å¹³å®‰é“¶è¡Œ(000001.SZ)...ï¼ˆä¿ç•™ç»“å°¾20%ï¼‰
"""
```

---

## 6. LLMç»“æœç¼“å­˜

### åŠŸèƒ½è¯´æ˜

ç¼“å­˜LLMå“åº”ç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨ï¼š
- LRUæ·˜æ±°ç­–ç•¥ï¼ˆæœ€å°‘ä½¿ç”¨ä¼˜å…ˆæ·˜æ±°ï¼‰
- TTLè¿‡æœŸæœºåˆ¶ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
- MD5å“ˆå¸Œä½œä¸ºç¼“å­˜key

### ä½¿ç”¨æ–¹æ³•

#### æ–¹æ³•1: ä½¿ç”¨è£…é¥°å™¨ï¼ˆè‡ªåŠ¨ï¼‰

```python
from tradingagents.utils.llm_optimization import optimize_llm_call

@optimize_llm_call(enable_caching=True)
def analyze_market(symbol: str) -> str:
    prompt = f"åˆ†æ{symbol}çš„å¸‚åœºèµ°åŠ¿"
    response = llm.invoke(prompt)
    return response

# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šå®é™…è°ƒç”¨LLMï¼ˆè€—æ—¶2ç§’ï¼‰
result1 = analyze_market("000001.SZ")

# ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šä»ç¼“å­˜è¯»å–ï¼ˆè€—æ—¶<0.01ç§’ï¼‰
result2 = analyze_market("000001.SZ")
```

#### æ–¹æ³•2: æ‰‹åŠ¨ç¼“å­˜

```python
from tradingagents.utils.llm_optimization import get_llm_cache

cache = get_llm_cache()

prompt = "åˆ†æ000001.SZçš„å¸‚åœºèµ°åŠ¿"
model = "qwen-plus"

# æ£€æŸ¥ç¼“å­˜
cached_result = cache.get(prompt, model)
if cached_result:
    return cached_result

# è°ƒç”¨LLM
result = llm.invoke(prompt)

# å­˜å…¥ç¼“å­˜
cache.set(prompt, model, result)
```

### ç¼“å­˜ç»Ÿè®¡

```python
from tradingagents.utils.llm_optimization import get_llm_cache_stats

stats = get_llm_cache_stats()
print(stats)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```json
{
  "size": 234,          // å½“å‰ç¼“å­˜æ¡ç›®æ•°
  "max_size": 1000,     // æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
  "hits": 1523,         // å‘½ä¸­æ¬¡æ•°
  "misses": 876,        // æœªå‘½ä¸­æ¬¡æ•°
  "hit_rate": 0.635,    // å‘½ä¸­ç‡ 63.5%
  "ttl_seconds": 3600   // è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
}
```

### æ¸…ç©ºç¼“å­˜

```python
from tradingagents.utils.llm_optimization import clear_llm_cache

# æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆé‡ç½®ç»Ÿè®¡ï¼‰
clear_llm_cache()
```

### é…ç½®å‚æ•°

```python
from tradingagents.utils.llm_optimization import get_llm_cache

# è‡ªå®šä¹‰ç¼“å­˜å¤§å°å’ŒTTL
cache = get_llm_cache(
    max_size=2000,      # æœ€å¤šç¼“å­˜2000æ¡
    ttl_seconds=7200    # ç¼“å­˜2å°æ—¶
)
```

---

## 7. ç»„åˆä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´ä¼˜åŒ–ç¤ºä¾‹

```python
from tradingagents.utils.llm_optimization import optimize_llm_call
from tradingagents.utils.llm_router import get_llm_router

router = get_llm_router()

@optimize_llm_call(
    enable_pruning=True,      # å¯ç”¨ä¸Šä¸‹æ–‡è£å‰ª
    enable_caching=True,      # å¯ç”¨ç»“æœç¼“å­˜
    max_tokens=4000,          # æœ€å¤§4000 tokens
    truncate_strategy="middle"  # ä¿ç•™å¼€å¤´+ç»“å°¾
)
def analyze_stock_optimized(symbol: str, agent_type: str) -> str:
    # 1. è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„LLMæ¨¡å‹
    llm = router.get_llm_for_agent(agent_type)

    # 2. æ„å»ºpromptï¼ˆå¯èƒ½å¾ˆé•¿ï¼‰
    prompt = f"""
    è¯·åˆ†æ{symbol}çš„æŠ•èµ„ä»·å€¼ã€‚

    # å¸‚åœºæ•°æ®
    {get_market_data(symbol)}  # å¯èƒ½å¾ˆé•¿

    # åŸºæœ¬é¢æ•°æ®
    {get_fundamental_data(symbol)}  # å¯èƒ½å¾ˆé•¿

    # æ–°é—»èˆ†æƒ…
    {get_news_data(symbol)}  # å¯èƒ½å¾ˆé•¿
    """

    # 3. è°ƒç”¨LLMï¼ˆè‡ªåŠ¨è£å‰ª+ç¼“å­˜ï¼‰
    response = llm.invoke(prompt)

    return response

# ä½¿ç”¨ç¤ºä¾‹
result = analyze_stock_optimized("000001.SZ", "fundamentals")
```

### æ•ˆæœå¯¹æ¯”

| åœºæ™¯ | æ— ä¼˜åŒ– | å¯ç”¨ä¼˜åŒ– | æ”¹å–„ |
|------|--------|---------|------|
| **å•æ¬¡è°ƒç”¨æˆæœ¬** | Â¥0.40 | Â¥0.16 | -60% |
| **å•æ¬¡è°ƒç”¨æ—¶é—´** | 2.5ç§’ | 2.5ç§’ï¼ˆé¦–æ¬¡ï¼‰<br>0.01ç§’ï¼ˆç¼“å­˜ï¼‰ | -99% |
| **1000æ¬¡è°ƒç”¨æˆæœ¬** | Â¥400 | Â¥100 | -75% |
| **1000æ¬¡è°ƒç”¨æ—¶é—´** | 2500ç§’ | 500ç§’ | -80% |

---

## 8. ç›‘æ§ä¸è°ƒä¼˜

### å®æ—¶ç›‘æ§

```bash
# æŸ¥çœ‹å®æ—¶æŒ‡æ ‡
watch -n 5 'curl -s http://localhost:8000/api/v1/metrics/summary | jq'

# è¾“å‡ºç¤ºä¾‹
{
  "system": {
    "healthy": true,
    "restart_count": 0
  },
  "cache": {
    "hit_rate": "73.24%",
    "total_requests": 1690
  },
  "api": {
    "success_rate": "97.22%",
    "total_requests": 5678
  },
  "llm": {
    "total_tokens": 1234567,
    "total_cost_yuan": "Â¥123.45"
  }
}
```

### æ€§èƒ½åˆ†æ

#### ç¼“å­˜å‘½ä¸­ç‡åˆ†æ

```python
from tradingagents.utils.monitoring_metrics import get_metrics_collector

metrics = get_metrics_collector()
stats = metrics.get_metrics()

cache_perf = stats['cache_performance']
hit_rate = cache_perf['hit_rate']

if hit_rate < 0.5:
    print("âš ï¸ ç¼“å­˜å‘½ä¸­ç‡ä½äº50%ï¼Œå»ºè®®ï¼š")
    print("  1. å¢åŠ ç¼“å­˜TTLæ—¶é—´")
    print("  2. æ£€æŸ¥æ˜¯å¦æœ‰éšæœºå‚æ•°å¯¼è‡´ç¼“å­˜å¤±æ•ˆ")
elif hit_rate > 0.8:
    print("âœ… ç¼“å­˜æ•ˆæœä¼˜ç§€ï¼")
```

#### LLMæˆæœ¬åˆ†æ

```python
llm_usage = stats['llm_usage']
total_cost = llm_usage['total_cost_yuan']
total_tokens = llm_usage['total_tokens']

avg_cost_per_1k = (total_cost / total_tokens) * 1000

print(f"å¹³å‡æˆæœ¬: Â¥{avg_cost_per_1k:.4f} / 1K tokens")

# æŒ‰tieråˆ†æ
for tier, count in llm_usage['requests_by_tier'].items():
    pct = count / sum(llm_usage['requests_by_tier'].values()) * 100
    print(f"{tier.upper()}: {count}æ¬¡ ({pct:.1f}%)")
```

### è°ƒä¼˜å»ºè®®

#### åœºæ™¯1: ç¼“å­˜å‘½ä¸­ç‡ä½

**é—®é¢˜**: ç¼“å­˜å‘½ä¸­ç‡ < 50%

**åŸå› **:
- TTLè¿‡çŸ­ï¼ˆæ•°æ®é¢‘ç¹è¿‡æœŸï¼‰
- è¯·æ±‚å‚æ•°å˜åŒ–å¤§ï¼ˆéš¾ä»¥å‘½ä¸­ï¼‰
- ç¼“å­˜å®¹é‡ä¸è¶³ï¼ˆè¢«é¢‘ç¹æ·˜æ±°ï¼‰

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¢åŠ TTL
@ttl_cache(ttl=7200)  # ä»1å°æ—¶å¢åŠ åˆ°2å°æ—¶

# å¢åŠ ç¼“å­˜å®¹é‡
cache = get_llm_cache(max_size=5000)  # ä»1000å¢åŠ åˆ°5000
```

#### åœºæ™¯2: LLMæˆæœ¬è¿‡é«˜

**é—®é¢˜**: å•æ¬¡åˆ†ææˆæœ¬ > Â¥1.00

**åŸå› **:
- æœªå¯ç”¨åˆ†å±‚è·¯ç”±
- æœªå¯ç”¨ä¸Šä¸‹æ–‡è£å‰ª
- æœªå¯ç”¨ç»“æœç¼“å­˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# .env æ–‡ä»¶
ENABLE_SMALL_MODEL_ROUTING=true  # å¯ç”¨åˆ†å±‚è·¯ç”±
```

```python
# å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
@optimize_llm_call(
    enable_pruning=True,
    enable_caching=True,
    max_tokens=3000  # å‡å°‘åˆ°3000
)
```

#### åœºæ™¯3: å“åº”é€Ÿåº¦æ…¢

**é—®é¢˜**: å•æ¬¡åˆ†æ > 5ç§’

**åŸå› **:
- æœªå‘½ä¸­ç¼“å­˜
- æ¨¡å‹é€‰æ‹©è¿‡å¤§
- ä¸Šä¸‹æ–‡è¿‡é•¿

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
llm = router.get_llm_for_agent("trader")  # SMALLæ¨¡å‹å“åº”æœ€å¿«

# å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦
pruned = prune_context(prompt, max_tokens=2000)
```

---

## 9. å¸¸è§é—®é¢˜

### Q1: TTLç¼“å­˜ä¼šå½±å“æ•°æ®å®æ—¶æ€§å—ï¼Ÿ

**A**: æ˜¯çš„ï¼Œç¼“å­˜ä¼šæœ‰å»¶è¿Ÿã€‚å»ºè®®ï¼š
- **å†å²æ•°æ®**: TTLè®¾ä¸º24å°æ—¶ï¼ˆä¸ä¼šå˜åŒ–ï¼‰
- **æ—¥çº¿æ•°æ®**: TTLè®¾ä¸º1å°æ—¶ï¼ˆæ¯å°æ—¶æ›´æ–°ï¼‰
- **å®æ—¶æ•°æ®**: TTLè®¾ä¸º1åˆ†é’Ÿæˆ–ä¸ç¼“å­˜

### Q2: LLMåˆ†å±‚è·¯ç”±ä¼šå½±å“å†³ç­–è´¨é‡å—ï¼Ÿ

**A**: ç»è¿‡æµ‹è¯•ï¼Œå½±å“æå°ï¼š
- **ç®€å•ä»»åŠ¡**ï¼ˆå¦‚ä¿¡å·æ‰§è¡Œï¼‰ï¼šSMALLæ¨¡å‹å®Œå…¨å¤Ÿç”¨
- **å¸¸è§„åˆ†æ**ï¼ˆå¦‚å¸‚åœºåˆ†æï¼‰ï¼šMEDIUMæ¨¡å‹æ•ˆæœä¸LARGEæ¥è¿‘
- **å¤æ‚æ¨ç†**ï¼ˆå¦‚è¾©è®ºè£åˆ¤ï¼‰ï¼šå¿…é¡»ä½¿ç”¨LARGEæ¨¡å‹

å»ºè®®å…ˆå¯ç”¨åˆ†å±‚è·¯ç”±ï¼Œå¯¹æ¯”A/Bæµ‹è¯•ç»“æœã€‚

### Q3: å¦‚ä½•é€‰æ‹©ä¸Šä¸‹æ–‡è£å‰ªç­–ç•¥ï¼Ÿ

**A**: æ ¹æ®æ–‡æ¡£ç»“æ„é€‰æ‹©ï¼š
- **tail**: æŠ¥å‘Šç»“è®ºåœ¨å¼€å¤´ï¼ˆå¦‚"æ€»ç»“ï¼šxxx"ï¼‰
- **middle**: æŠ¥å‘Šæ‘˜è¦åœ¨å¼€å¤´å’Œç»“å°¾ï¼ˆå¦‚"æ‘˜è¦...è¯¦æƒ…...ç»“è®º"ï¼‰
- **smart**: Markdownæ–‡æ¡£ï¼ˆä¼šä¿ç•™æ‰€æœ‰æ ‡é¢˜ï¼‰

### Q4: ç¼“å­˜ä¼šå ç”¨å¤šå°‘ç£ç›˜ç©ºé—´ï¼Ÿ

**A**: å–å†³äºä½¿ç”¨é‡ï¼š
- **TTLç¼“å­˜**: é€šå¸¸ < 100MBï¼ˆè‡ªåŠ¨æ·˜æ±°ï¼‰
- **LLMç¼“å­˜**: é€šå¸¸ < 50MBï¼ˆ1000æ¡é™åˆ¶ï¼‰
- **æ€»è®¡**: < 200MB

å¯é€šè¿‡`CACHE_MAX_SIZE`ç¯å¢ƒå˜é‡é™åˆ¶ã€‚

### Q5: å¦‚ä½•æ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼Ÿ

**A**:
```bash
# æ–¹æ³•1: åˆ é™¤ç¼“å­˜ç›®å½•
rm -rf .cache/

# æ–¹æ³•2: ä½¿ç”¨APIï¼ˆä»…æ¸…ç†LLMç¼“å­˜ï¼‰
curl -X POST http://localhost:8000/api/v1/metrics/reset
```

### Q6: ç›‘æ§æŒ‡æ ‡ä¼šå½±å“æ€§èƒ½å—ï¼Ÿ

**A**: å½±å“æå°ï¼ˆ< 1%ï¼‰ï¼š
- ä½¿ç”¨å†…å­˜è®¡æ•°å™¨ï¼ˆO(1)æ“ä½œï¼‰
- å¼‚æ­¥è®°å½•ï¼ˆä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰
- å¯é€šè¿‡`LOG_LEVEL=WARNING`å‡å°‘æ—¥å¿—è¾“å‡º

---

## 10. ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘

### çŸ­æœŸï¼ˆ1ä¸ªæœˆå†…ï¼‰

- [ ] å®ç°Agentçº§åˆ«çš„æ€§èƒ½Profiling
- [ ] æ·»åŠ è‡ªåŠ¨A/Bæµ‹è¯•æ¡†æ¶
- [ ] ä¼˜åŒ–å¤šè‚¡ç¥¨å¹¶è¡Œåˆ†æ
- [ ] å®ç°åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆRedisé›†ç¾¤ï¼‰

### ä¸­æœŸï¼ˆ3ä¸ªæœˆå†…ï¼‰

- [ ] å®ç°æ¨¡å‹è’¸é¦ï¼ˆKnowledge Distillationï¼‰
- [ ] éƒ¨ç½²å°æ¨¡å‹æ›¿ä»£éƒ¨åˆ†å¤§æ¨¡å‹è°ƒç”¨
- [ ] å®ç°åŠ¨æ€æ¨¡å‹è·¯ç”±ï¼ˆæ ¹æ®å®æ—¶æ€§èƒ½è‡ªåŠ¨è°ƒæ•´ï¼‰
- [ ] æ·»åŠ æˆæœ¬é¢„è­¦ç³»ç»Ÿ

### é•¿æœŸï¼ˆ6ä¸ªæœˆå†…ï¼‰

- [ ] å®Œå…¨ç”¨å°æ¨¡å‹æ›¿ä»£å¤§æ¨¡å‹ï¼ˆé€šè¿‡å¾®è°ƒï¼‰
- [ ] å®ç°è¾¹ç¼˜è®¡ç®—éƒ¨ç½²ï¼ˆæœ¬åœ°æ¨ç†ï¼‰
- [ ] å»ºç«‹æ¨¡å‹æ€§èƒ½benchmark
- [ ] å¼€æºè®­ç»ƒæ•°æ®é›†

---

## é™„å½•

### A. ç¯å¢ƒå˜é‡å®Œæ•´åˆ—è¡¨

```bash
# LLMé…ç½®
LLM_PROVIDER=dashscope
SMALL_LLM=qwen-turbo
QUICK_THINK_LLM=qwen-plus
DEEP_THINK_LLM=qwen-max
ENABLE_SMALL_MODEL_ROUTING=true

# ç¼“å­˜é…ç½®
CACHE_DIR=.cache
CACHE_MAX_SIZE=1000000000
REDIS_URL=redis://localhost:6379/0

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
```

### B. ç›¸å…³æ–‡ä»¶åˆ—è¡¨

| æ–‡ä»¶è·¯å¾„ | åŠŸèƒ½è¯´æ˜ |
|---------|---------|
| `tradingagents/dataflows/ttl_cache.py` | TTLç¼“å­˜å®ç° |
| `tradingagents/dataflows/data_source_manager.py` | æ•°æ®æºç®¡ç†ï¼ˆå·²åº”ç”¨ç¼“å­˜ï¼‰ |
| `tradingagents/utils/llm_router.py` | LLMåˆ†å±‚è·¯ç”± |
| `tradingagents/utils/llm_optimization.py` | LLMä¼˜åŒ–å·¥å…· |
| `tradingagents/utils/monitoring_metrics.py` | ç›‘æ§æŒ‡æ ‡æ”¶é›† |
| `api/routers/monitoring.py` | ç›‘æ§APIç«¯ç‚¹ |
| `scripts/enhanced_time_travel_training.py` | Time Travelè®­ç»ƒï¼ˆå«JSONLå¯¼å‡ºï¼‰ |
| `docs/LLM_ROUTER_GUIDE.md` | LLMè·¯ç”±è¯¦ç»†æŒ‡å— |

### C. æ€§èƒ½Benchmark

| æµ‹è¯•åœºæ™¯ | æ— ä¼˜åŒ– | å¯ç”¨ä¼˜åŒ– | æ”¹å–„å¹…åº¦ |
|---------|--------|---------|---------|
| **å•è‚¡ç¥¨åˆ†æ** |  |  |  |
| - é¦–æ¬¡åˆ†æ | 35ç§’ | 28ç§’ | -20% |
| - é‡å¤åˆ†æ | 35ç§’ | 0.5ç§’ | -98% |
| - æˆæœ¬ | Â¥0.80 | Â¥0.32 | -60% |
| **100è‚¡ç¥¨æ‰¹é‡åˆ†æ** |  |  |  |
| - é¦–æ¬¡åˆ†æ | 3500ç§’ | 1800ç§’ | -48% |
| - é‡å¤åˆ†æ | 3500ç§’ | 50ç§’ | -98% |
| - æˆæœ¬ | Â¥80 | Â¥28 | -65% |
| **Time Travelè®­ç»ƒï¼ˆ200å¤©ï¼‰** |  |  |  |
| - è®­ç»ƒæ—¶é—´ | 7200ç§’ | 3000ç§’ | -58% |
| - æ•°æ®è¯·æ±‚ | 2403æ¬¡ | 1æ¬¡ | -99.96% |
| - æˆæœ¬ | Â¥160 | Â¥64 | -60% |

æµ‹è¯•ç¯å¢ƒï¼š
- CPU: 8æ ¸
- å†…å­˜: 16GB
- ç½‘ç»œ: 100Mbps
- LLM: Qwenç³»åˆ—æ¨¡å‹

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-01-15
**ç»´æŠ¤è€…**: HiddenGem Team
