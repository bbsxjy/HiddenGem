import os

DEFAULT_CONFIG = {
    "project_dir": os.path.abspath(os.path.join(os.path.dirname(__file__), ".")),
    "results_dir": os.getenv("TRADINGAGENTS_RESULTS_DIR", "./results"),
    "data_dir": os.path.join(os.path.expanduser("~"), "Documents", "TradingAgents", "data"),
    "data_cache_dir": os.path.join(
        os.path.abspath(os.path.join(os.path.dirname(__file__), ".")),
        "dataflows/data_cache",
    ),
    # LLM settings - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæ”¯æŒSiliconFlowç­‰è‡ªå®šä¹‰æä¾›å•†
    "llm_provider": os.getenv("LLM_PROVIDER", "openai"),

    # ğŸ†• ä¸‰å±‚LLMæ¨¡å‹é…ç½®
    "small_llm": os.getenv("SMALL_LLM", "gpt-4o-mini"),        # å°æ¨¡å‹ï¼šç®€å•ä»»åŠ¡ï¼ˆå¦‚æ ¼å¼åŒ–ï¼‰
    "quick_think_llm": os.getenv("QUICK_THINK_LLM", "gpt-4o-mini"),  # ä¸­æ¨¡å‹ï¼šå¸¸è§„åˆ†æ
    "deep_think_llm": os.getenv("DEEP_THINK_LLM", "o4-mini"),        # å¤§æ¨¡å‹ï¼šå¤æ‚æ¨ç†

    # ğŸ†• å°æ¨¡å‹è·¯ç”±å¼€å…³ï¼ˆé»˜è®¤å…³é—­ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
    "enable_small_model_routing": os.getenv("ENABLE_SMALL_MODEL_ROUTING", "false").lower() == "true",

    "backend_url": os.getenv("BACKEND_URL", "https://api.openai.com/v1"),
    # Debate and discussion settings
    "max_debate_rounds": 1,
    "max_risk_discuss_rounds": 1,
    "max_recur_limit": 100,
    # Tool settings - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæä¾›é»˜è®¤å€¼
    "online_tools": os.getenv("ONLINE_TOOLS_ENABLED", "false").lower() == "true",
    "online_news": os.getenv("ONLINE_NEWS_ENABLED", "true").lower() == "true", 
    "realtime_data": os.getenv("REALTIME_DATA_ENABLED", "false").lower() == "true",

    # Note: Database and cache configuration is now managed by .env file and config.database_manager
    # No database/cache settings in default config to avoid configuration conflicts
}
