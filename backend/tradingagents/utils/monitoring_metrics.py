"""
Monitoring Metrics Module

æä¾›Prometheusé£æ ¼çš„ç›‘æ§æŒ‡æ ‡æ”¶é›†å’ŒREST APIæš´éœ²åŠŸèƒ½ã€‚

ç›‘æ§æŒ‡æ ‡åŒ…æ‹¬:
- ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ˆå¿ƒè·³ã€é‡å¯æ¬¡æ•°ï¼‰
- ç¼“å­˜æ€§èƒ½ï¼ˆå‘½ä¸­ç‡ã€æ€»è¯·æ±‚æ•°ï¼‰
- APIè°ƒç”¨ç»Ÿè®¡ï¼ˆæˆåŠŸ/å¤±è´¥æ¬¡æ•°ã€å¹³å‡è€—æ—¶ï¼‰
- LLMä½¿ç”¨ç»Ÿè®¡ï¼ˆtokenæ¶ˆè€—ã€æˆæœ¬ï¼‰
- ä»»åŠ¡è¿›åº¦ï¼ˆTime Travelè®­ç»ƒè¿›åº¦ï¼‰
"""

import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict
from threading import Lock

from tradingagents.utils.logging_init import get_logger
logger = get_logger("monitoring")


@dataclass
class Counter:
    """ç®€å•è®¡æ•°å™¨"""
    name: str
    help: str
    value: int = 0
    labels: Dict[str, str] = field(default_factory=dict)

    def inc(self, amount: int = 1):
        """å¢åŠ è®¡æ•°"""
        self.value += amount

    def reset(self):
        """é‡ç½®è®¡æ•°"""
        self.value = 0


@dataclass
class Gauge:
    """ç®€å•ä»ªè¡¨"""
    name: str
    help: str
    value: float = 0.0
    labels: Dict[str, str] = field(default_factory=dict)

    def set(self, value: float):
        """è®¾ç½®å€¼"""
        self.value = value

    def inc(self, amount: float = 1.0):
        """å¢åŠ å€¼"""
        self.value += amount

    def dec(self, amount: float = 1.0):
        """å‡å°‘å€¼"""
        self.value -= amount


@dataclass
class Histogram:
    """ç®€å•ç›´æ–¹å›¾ï¼ˆç”¨äºè®°å½•å»¶è¿Ÿï¼‰"""
    name: str
    help: str
    buckets: List[float] = field(default_factory=lambda: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0])
    values: List[float] = field(default_factory=list)
    labels: Dict[str, str] = field(default_factory=dict)

    def observe(self, value: float):
        """è®°å½•è§‚æµ‹å€¼"""
        self.values.append(value)

    def get_summary(self) -> Dict[str, float]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        if not self.values:
            return {"count": 0, "sum": 0, "min": 0, "max": 0, "avg": 0}

        return {
            "count": len(self.values),
            "sum": sum(self.values),
            "min": min(self.values),
            "max": max(self.values),
            "avg": sum(self.values) / len(self.values)
        }


class MetricsCollector:
    """ç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨"""
        self._lock = Lock()

        # ===== ç³»ç»Ÿå¥åº·æŒ‡æ ‡ =====
        self.heartbeat_status = Gauge(
            name="auto_trading_heartbeat_seconds",
            help="Seconds since last heartbeat from auto trading loop"
        )

        self.restart_count = Counter(
            name="auto_trading_restart_total",
            help="Total number of auto trading loop restarts"
        )

        self.health_status = Gauge(
            name="auto_trading_health_status",
            help="Health status of auto trading (1=healthy, 0=unhealthy)"
        )

        # ===== ç¼“å­˜æ€§èƒ½æŒ‡æ ‡ =====
        self.cache_hits = Counter(
            name="data_cache_hits_total",
            help="Total number of cache hits"
        )

        self.cache_misses = Counter(
            name="data_cache_misses_total",
            help="Total number of cache misses"
        )

        self.cache_hit_rate = Gauge(
            name="data_cache_hit_rate",
            help="Cache hit rate (0.0 to 1.0)"
        )

        # ===== APIè°ƒç”¨ç»Ÿè®¡ =====
        self.api_requests_total = Counter(
            name="api_requests_total",
            help="Total number of API requests"
        )

        self.api_requests_success = Counter(
            name="api_requests_success_total",
            help="Total number of successful API requests"
        )

        self.api_requests_failure = Counter(
            name="api_requests_failure_total",
            help="Total number of failed API requests"
        )

        self.api_request_duration = Histogram(
            name="api_request_duration_seconds",
            help="API request duration in seconds"
        )

        # ===== LLMä½¿ç”¨ç»Ÿè®¡ =====
        self.llm_tokens_total = Counter(
            name="llm_tokens_total",
            help="Total number of LLM tokens consumed"
        )

        self.llm_cost_total = Gauge(
            name="llm_cost_total_yuan",
            help="Total LLM cost in CNY"
        )

        self.llm_requests_by_tier = defaultdict(lambda: Counter(
            name="llm_requests_by_tier_total",
            help="LLM requests by tier (small/medium/large)"
        ))

        # ===== ä»»åŠ¡è¿›åº¦æŒ‡æ ‡ =====
        self.task_progress = Gauge(
            name="task_progress_ratio",
            help="Task progress ratio (0.0 to 1.0)"
        )

        self.task_completed_steps = Counter(
            name="task_completed_steps_total",
            help="Total completed steps in current task"
        )

        # ===== æ•°æ®æºç»Ÿè®¡ =====
        self.data_source_requests = defaultdict(lambda: Counter(
            name="data_source_requests_total",
            help="Data source requests by provider"
        ))

        self.data_source_failures = defaultdict(lambda: Counter(
            name="data_source_failures_total",
            help="Data source failures by provider"
        ))

        logger.info("ğŸ“Š Metrics Collector initialized")

    def record_heartbeat(self, last_heartbeat: Optional[datetime]):
        """è®°å½•å¿ƒè·³æ—¶é—´"""
        if last_heartbeat:
            elapsed = (datetime.now() - last_heartbeat).total_seconds()
            self.heartbeat_status.set(elapsed)

    def record_restart(self):
        """è®°å½•é‡å¯äº‹ä»¶"""
        with self._lock:
            self.restart_count.inc()

    def record_health(self, is_healthy: bool):
        """è®°å½•å¥åº·çŠ¶æ€"""
        self.health_status.set(1.0 if is_healthy else 0.0)

    def record_cache_hit(self):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        with self._lock:
            self.cache_hits.inc()
            self._update_cache_hit_rate()

    def record_cache_miss(self):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        with self._lock:
            self.cache_misses.inc()
            self._update_cache_hit_rate()

    def _update_cache_hit_rate(self):
        """æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.cache_hits.value + self.cache_misses.value
        if total > 0:
            hit_rate = self.cache_hits.value / total
            self.cache_hit_rate.set(hit_rate)

    def record_api_request(self, success: bool, duration: float):
        """è®°å½•APIè¯·æ±‚"""
        with self._lock:
            self.api_requests_total.inc()
            if success:
                self.api_requests_success.inc()
            else:
                self.api_requests_failure.inc()
            self.api_request_duration.observe(duration)

    def record_llm_usage(self, tokens: int, cost: float, tier: str = "medium"):
        """è®°å½•LLMä½¿ç”¨"""
        with self._lock:
            self.llm_tokens_total.inc(tokens)
            self.llm_cost_total.inc(cost)
            self.llm_requests_by_tier[tier].inc()

    def record_task_progress(self, progress: float, completed_steps: int):
        """è®°å½•ä»»åŠ¡è¿›åº¦"""
        self.task_progress.set(progress)
        self.task_completed_steps.value = completed_steps

    def record_data_source_request(self, provider: str, success: bool):
        """è®°å½•æ•°æ®æºè¯·æ±‚"""
        with self._lock:
            self.data_source_requests[provider].inc()
            if not success:
                self.data_source_failures[provider].inc()

    def get_metrics(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æŒ‡æ ‡ï¼ˆREST APIæ ¼å¼ï¼‰

        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        with self._lock:
            # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
            cache_total = self.cache_hits.value + self.cache_misses.value
            cache_hit_rate = (self.cache_hits.value / cache_total) if cache_total > 0 else 0.0

            # è®¡ç®—APIæˆåŠŸç‡
            api_total = self.api_requests_total.value
            api_success_rate = (self.api_requests_success.value / api_total) if api_total > 0 else 0.0

            return {
                "timestamp": datetime.now().isoformat(),
                "system_health": {
                    "heartbeat_seconds": self.heartbeat_status.value,
                    "restart_count": self.restart_count.value,
                    "is_healthy": self.health_status.value == 1.0,
                },
                "cache_performance": {
                    "hits": self.cache_hits.value,
                    "misses": self.cache_misses.value,
                    "total": cache_total,
                    "hit_rate": cache_hit_rate,
                },
                "api_statistics": {
                    "total_requests": api_total,
                    "successful_requests": self.api_requests_success.value,
                    "failed_requests": self.api_requests_failure.value,
                    "success_rate": api_success_rate,
                    "duration_stats": self.api_request_duration.get_summary(),
                },
                "llm_usage": {
                    "total_tokens": self.llm_tokens_total.value,
                    "total_cost_yuan": self.llm_cost_total.value,
                    "requests_by_tier": {
                        tier: counter.value
                        for tier, counter in self.llm_requests_by_tier.items()
                    },
                },
                "task_progress": {
                    "progress_ratio": self.task_progress.value,
                    "completed_steps": self.task_completed_steps.value,
                },
                "data_sources": {
                    provider: {
                        "total_requests": self.data_source_requests[provider].value,
                        "failed_requests": self.data_source_failures[provider].value,
                    }
                    for provider in self.data_source_requests.keys()
                },
            }

    def get_prometheus_format(self) -> str:
        """
        è·å–Prometheusæ–‡æœ¬æ ¼å¼æŒ‡æ ‡

        Returns:
            Prometheusæ ¼å¼çš„æŒ‡æ ‡æ–‡æœ¬
        """
        lines = []

        # Helper function to add metric
        def add_metric(metric_type: str, metric):
            lines.append(f"# HELP {metric.name} {metric.help}")
            lines.append(f"# TYPE {metric.name} {metric_type}")
            if hasattr(metric, 'value'):
                lines.append(f"{metric.name} {metric.value}")
            lines.append("")

        # System health
        add_metric("gauge", self.heartbeat_status)
        add_metric("counter", self.restart_count)
        add_metric("gauge", self.health_status)

        # Cache performance
        add_metric("counter", self.cache_hits)
        add_metric("counter", self.cache_misses)
        add_metric("gauge", self.cache_hit_rate)

        # API statistics
        add_metric("counter", self.api_requests_total)
        add_metric("counter", self.api_requests_success)
        add_metric("counter", self.api_requests_failure)

        # Histogram for API duration
        summary = self.api_request_duration.get_summary()
        lines.append(f"# HELP {self.api_request_duration.name} {self.api_request_duration.help}")
        lines.append(f"# TYPE {self.api_request_duration.name} histogram")
        lines.append(f"{self.api_request_duration.name}_count {summary['count']}")
        lines.append(f"{self.api_request_duration.name}_sum {summary['sum']}")
        lines.append("")

        # LLM usage
        add_metric("counter", self.llm_tokens_total)
        add_metric("gauge", self.llm_cost_total)

        for tier, counter in self.llm_requests_by_tier.items():
            lines.append(f"# HELP {counter.name} {counter.help}")
            lines.append(f"# TYPE {counter.name} counter")
            lines.append(f'{counter.name}{{tier="{tier}"}} {counter.value}')
            lines.append("")

        # Task progress
        add_metric("gauge", self.task_progress)
        add_metric("counter", self.task_completed_steps)

        # Data sources
        for provider, counter in self.data_source_requests.items():
            lines.append(f"# HELP {counter.name} {counter.help}")
            lines.append(f"# TYPE {counter.name} counter")
            lines.append(f'{counter.name}{{provider="{provider}"}} {counter.value}')
            lines.append("")

        for provider, counter in self.data_source_failures.items():
            lines.append(f"# HELP {counter.name} {counter.help}")
            lines.append(f"# TYPE {counter.name} counter")
            lines.append(f'{counter.name}{{provider="{provider}"}} {counter.value}')
            lines.append("")

        return "\n".join(lines)

    def reset(self):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        with self._lock:
            self.cache_hits.reset()
            self.cache_misses.reset()
            self.api_requests_total.reset()
            self.api_requests_success.reset()
            self.api_requests_failure.reset()
            self.llm_tokens_total.reset()
            self.restart_count.reset()
            self.task_completed_steps.reset()
            self.llm_requests_by_tier.clear()
            self.data_source_requests.clear()
            self.data_source_failures.clear()
            logger.info("ğŸ“Š All metrics reset")


# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
_global_metrics: Optional[MetricsCollector] = None


def get_metrics_collector() -> MetricsCollector:
    """
    è·å–å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        MetricsCollectorå®ä¾‹
    """
    global _global_metrics

    if _global_metrics is None:
        _global_metrics = MetricsCollector()

    return _global_metrics


def reset_metrics_collector():
    """é‡ç½®å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _global_metrics
    if _global_metrics:
        _global_metrics.reset()
    _global_metrics = None
