# RL Agent Training Guide

## æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•ä½¿ç”¨çœŸå®å¸‚åœºæ•°æ®è®­ç»ƒå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰äº¤æ˜“Agentã€‚

## æ–‡ä»¶è¯´æ˜

- **train_rl_agent.py**: å®Œæ•´è®­ç»ƒè„šæœ¬ï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰
  - ä½¿ç”¨å¤šåªAè‚¡æ•°æ®ï¼ˆ6åªï¼‰
  - è®­ç»ƒå‘¨æœŸ: 2025-01-01 è‡³ 2025-10-31
  - è®­ç»ƒæ­¥æ•°: 100,000æ­¥
  - è®­ç»ƒæ—¶é—´: çº¦30-60åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰

- **train_rl_quick_test.py**: å¿«é€Ÿæµ‹è¯•è„šæœ¬
  - ä»…ä½¿ç”¨1åªè‚¡ç¥¨ï¼ˆ000001å¹³å®‰é“¶è¡Œï¼‰
  - è®­ç»ƒå‘¨æœŸ: 2025-01-01 è‡³ 2025-03-31
  - è®­ç»ƒæ­¥æ•°: 10,000æ­¥
  - è®­ç»ƒæ—¶é—´: çº¦5-10åˆ†é’Ÿ

## ç¯å¢ƒè¦æ±‚

### å®‰è£…ä¾èµ–

```bash
# å®‰è£…stable-baselines3åŠå…¶ä¾èµ–
pip install stable-baselines3[extra]

# æˆ–è€…ä»requirementsæ–‡ä»¶å®‰è£…
pip install -r requirements.txt
```

### æ‰€éœ€PythonåŒ…

- `stable-baselines3`: PPOç®—æ³•å®ç°
- `gymnasium`: OpenAI Gymçš„æ–°ç‰ˆæœ¬
- `pandas`, `numpy`: æ•°æ®å¤„ç†
- `torch`: PyTorchï¼ˆstable-baselines3ä¾èµ–ï¼‰

## å¿«é€Ÿå¼€å§‹

### 1. å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èå…ˆè¿è¡Œï¼‰

```bash
cd backend
python scripts/train_rl_quick_test.py
```

**é¢„æœŸè¾“å‡º:**
```
ğŸ§ª RL Agentå¿«é€Ÿæµ‹è¯•è®­ç»ƒ
============================================================
ğŸš€ RLè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ
   è®­ç»ƒè‚¡ç¥¨: 000001
   è®­ç»ƒå‘¨æœŸ: 2025-01-01 è‡³ 2025-03-31
   åˆå§‹èµ„é‡‘: Â¥100,000
   æ¨¡å‹è·¯å¾„: models/ppo_trading_agent_test.zip

ğŸ“Š è·å–000001å¸‚åœºæ•°æ®...
âœ… æˆåŠŸè·å–000001æ•°æ®: 60æ¡è®°å½•
   æ—¶é—´èŒƒå›´: 2025-01-01 è‡³ 2025-03-31
   ä»·æ ¼èŒƒå›´: Â¥12.50 - Â¥14.80

ğŸ¯ å¼€å§‹è®­ç»ƒRLæ¨¡å‹...
   æ€»æ­¥æ•°: 10,000
   å­¦ä¹ ç‡: 0.0003
   æ‰¹æ¬¡å¤§å°: 64

ğŸƒ å¼€å§‹è®­ç»ƒ...
[è¿›åº¦æ¡æ˜¾ç¤º...]
âœ… è®­ç»ƒå®Œæˆï¼è€—æ—¶: 0:08:23

ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: models/ppo_trading_agent_test.zip
ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...
   Episode 1: æ”¶ç›Šç‡=3.45%, æœ€ç»ˆä»·å€¼=Â¥103,450.00
   Episode 2: æ”¶ç›Šç‡=2.12%, æœ€ç»ˆä»·å€¼=Â¥102,120.00
   ...

ğŸ“ˆ è¯„ä¼°ç»“æœ:
   å¹³å‡å¥–åŠ±: 0.1234
   å¹³å‡æ”¶ç›Šç‡: 2.78%
   æ”¶ç›Šç‡æ ‡å‡†å·®: 1.23%
   æœ€ä½³æ”¶ç›Šç‡: 4.56%
   æœ€å·®æ”¶ç›Šç‡: 0.89%

============================================================
âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼
```

### 2. å®Œæ•´è®­ç»ƒ

å¦‚æœå¿«é€Ÿæµ‹è¯•æˆåŠŸï¼Œè¿è¡Œå®Œæ•´è®­ç»ƒ:

```bash
cd backend
python scripts/train_rl_agent.py
```

**è®­ç»ƒå‚æ•°:**
- è‚¡ç¥¨: 6åªAè‚¡ï¼ˆå¹³å®‰é“¶è¡Œã€ä¸‡ç§‘Aã€è´µå·èŒ…å°ã€æ‹›å•†é“¶è¡Œã€äº”ç²®æ¶²ã€å®å¾·æ—¶ä»£ï¼‰
- å‘¨æœŸ: 2025-01-01 è‡³ 2025-10-31ï¼ˆ10ä¸ªæœˆï¼‰
- æ­¥æ•°: 100,000æ­¥
- æ—¶é—´: çº¦30-60åˆ†é’Ÿ

**é¢„æœŸè¾“å‡º:**
```
ğŸš€ RL Agentè®­ç»ƒè„šæœ¬
================================================================================
ğŸš€ RLè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ
   è®­ç»ƒè‚¡ç¥¨: 000001, 000002, 600519, 600036, 000858, 300750
   è®­ç»ƒå‘¨æœŸ: 2025-01-01 è‡³ 2025-10-31
   åˆå§‹èµ„é‡‘: Â¥100,000
   æ¨¡å‹è·¯å¾„: models/ppo_trading_agent.zip

ğŸ“ˆ å¼€å§‹åˆ›å»ºè®­ç»ƒæ•°æ®...
ğŸ“Š è·å–000001å¸‚åœºæ•°æ®...
âœ… æˆåŠŸè·å–000001æ•°æ®: 200æ¡è®°å½•
ğŸ“Š è·å–000002å¸‚åœºæ•°æ®...
âœ… æˆåŠŸè·å–000002æ•°æ®: 198æ¡è®°å½•
...
âœ… è®­ç»ƒæ•°æ®åˆ›å»ºå®Œæˆ: 1,196æ¡è®°å½•
   æ¥è‡ª6åªè‚¡ç¥¨

ğŸ¯ å¼€å§‹è®­ç»ƒRLæ¨¡å‹...
   æ€»æ­¥æ•°: 100,000
   å­¦ä¹ ç‡: 0.0003
   æ‰¹æ¬¡å¤§å°: 64

ğŸƒ å¼€å§‹è®­ç»ƒ...
[è¿›åº¦æ¡æ˜¾ç¤º...]
âœ… è®­ç»ƒå®Œæˆï¼è€—æ—¶: 0:45:12

ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: models/ppo_trading_agent.zip
ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...
ğŸ“ˆ è¯„ä¼°ç»“æœ:
   å¹³å‡å¥–åŠ±: 0.2156
   å¹³å‡æ”¶ç›Šç‡: 5.34%
   æ”¶ç›Šç‡æ ‡å‡†å·®: 2.45%
   æœ€ä½³æ”¶ç›Šç‡: 9.12%
   æœ€å·®æ”¶ç›Šç‡: 1.23%

================================================================================
ğŸ‰ è®­ç»ƒå®Œæˆï¼
================================================================================
âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: models/ppo_trading_agent.zip
ğŸ“Š ç°åœ¨å¯ä»¥åœ¨å›æµ‹ç³»ç»Ÿä¸­ä½¿ç”¨RLç­–ç•¥äº†
```

## è®­ç»ƒå‚æ•°è¯´æ˜

### RLTrainerå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|-------|------|
| `symbols` | 6åªAè‚¡ | è®­ç»ƒè‚¡ç¥¨åˆ—è¡¨ |
| `start_date` | 2025-01-01 | å¼€å§‹æ—¥æœŸ |
| `end_date` | 2025-10-31 | ç»“æŸæ—¥æœŸ |
| `initial_cash` | 100,000 | åˆå§‹èµ„é‡‘ï¼ˆå…ƒï¼‰ |
| `model_save_path` | models/ppo_trading_agent.zip | æ¨¡å‹ä¿å­˜è·¯å¾„ |

### PPOè®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|-------|------|
| `total_timesteps` | 100,000 | æ€»è®­ç»ƒæ­¥æ•°ï¼ˆè¶Šå¤šè¶Šå¥½ï¼Œä½†è€—æ—¶æ›´é•¿ï¼‰ |
| `learning_rate` | 0.0003 | å­¦ä¹ ç‡ |
| `n_steps` | 2,048 | æ¯æ¬¡rolloutçš„æ­¥æ•° |
| `batch_size` | 64 | æ‰¹æ¬¡å¤§å° |
| `n_epochs` | 10 | æ¯æ¬¡æ›´æ–°çš„epochæ•° |
| `gamma` | 0.99 | æŠ˜æ‰£å› å­ï¼ˆæœªæ¥å¥–åŠ±çš„æƒé‡ï¼‰ |
| `gae_lambda` | 0.95 | GAE lambdaï¼ˆä¼˜åŠ¿ä¼°è®¡ï¼‰ |
| `clip_range` | 0.2 | PPO clipèŒƒå›´ |

## æ¨¡å‹è¾“å‡º

### æ¨¡å‹æ–‡ä»¶

- **ppo_trading_agent.zip**: è®­ç»ƒå¥½çš„PPOæ¨¡å‹
- **ppo_trading_agent_vecnormalize.pkl**: æ ‡å‡†åŒ–å‚æ•°ï¼ˆé‡è¦ï¼ï¼‰

### æ—¥å¿—æ–‡ä»¶

- **logs/ppo_tensorboard/**: TensorBoardæ—¥å¿—ï¼ˆå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼‰
- **logs/ppo_checkpoints/**: è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆæ¯10,000æ­¥ä¿å­˜ï¼‰

### æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼ˆTensorBoardï¼‰

```bash
# å®‰è£…tensorboard
pip install tensorboard

# å¯åŠ¨TensorBoard
tensorboard --logdir=logs/ppo_tensorboard

# åœ¨æµè§ˆå™¨è®¿é—®
# http://localhost:6006
```

## åœ¨å›æµ‹ç³»ç»Ÿä¸­ä½¿ç”¨

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `models/ppo_trading_agent.zip`ã€‚

RLStrategyä¼šè‡ªåŠ¨åŠ è½½è¿™ä¸ªæ¨¡å‹:

```python
# backend/trading/rl_strategy.py
class RLStrategy(BaseStrategy):
    def __init__(self, model_path: str = 'models/ppo_trading_agent.zip'):
        # è‡ªåŠ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        self.model = PPO.load(model_path)
```

åœ¨å›æµ‹ç³»ç»Ÿä¸­ä½¿ç”¨:

```bash
# è¿è¡Œå›æµ‹ï¼ˆå‰ç«¯ç•Œé¢ï¼‰
# 1. å¯åŠ¨åç«¯
cd backend
uvicorn api.main:app --reload

# 2. å¯åŠ¨å‰ç«¯
cd frontend
npm run dev

# 3. åœ¨æµè§ˆå™¨ä¸­è®¿é—®å›æµ‹é¡µé¢
# 4. é€‰æ‹©"RL"ç­–ç•¥
# 5. ç‚¹å‡»"å¼€å§‹å›æµ‹"
```

## è°ƒä¼˜å»ºè®®

### æå‡æ¨¡å‹æ€§èƒ½

1. **å¢åŠ è®­ç»ƒæ­¥æ•°**
   ```python
   total_timesteps=200000  # ä»100,000å¢åŠ åˆ°200,000
   ```

2. **è°ƒæ•´å­¦ä¹ ç‡**
   ```python
   learning_rate=0.0001  # é™ä½å­¦ä¹ ç‡ï¼ˆæ›´ç¨³å®šï¼‰
   # æˆ–
   learning_rate=0.001   # æé«˜å­¦ä¹ ç‡ï¼ˆæ›´å¿«æ”¶æ•›ï¼‰
   ```

3. **å¢åŠ è®­ç»ƒæ•°æ®**
   ```python
   # æ·»åŠ æ›´å¤šè‚¡ç¥¨
   symbols=[
       "000001", "000002", "600519", "600036",
       "000858", "300750", "601318", "000333",
       "002594", "601012"  # å¢åŠ 4åª
   ]
   ```

4. **è°ƒæ•´å¥–åŠ±å‡½æ•°**

   ç¼–è¾‘ `backend/trading/simple_trading_env.py`:
   ```python
   def _calculate_reward(self, begin_value, end_value, action):
       # ä¿®æ”¹å¥–åŠ±æƒé‡
       reward = return_pct * 200  # å¢åŠ æ”¶ç›Šå¥–åŠ±æƒé‡

       if self.shares_held > 0:
           reward += 0.05  # å¢åŠ æŒä»“å¥–åŠ±

       if action != 0:
           reward -= 0.01  # é™ä½äº¤æ˜“æƒ©ç½š
   ```

### è§£å†³è¿‡æ‹Ÿåˆ

1. **å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§**
   - åŒ…å«ä¸åŒæ¿å—çš„è‚¡ç¥¨
   - åŒ…å«ä¸åŒå¸‚å€¼çš„è‚¡ç¥¨
   - ä½¿ç”¨æ›´é•¿çš„è®­ç»ƒå‘¨æœŸ

2. **ä½¿ç”¨æ­£åˆ™åŒ–**
   ```python
   model = PPO(
       ...
       ent_coef=0.01,  # æ·»åŠ ç†µå¥–åŠ±ï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰
       vf_coef=0.5,    # å€¼å‡½æ•°æƒé‡
   )
   ```

3. **æ—©åœç­–ç•¥**
   ```python
   from stable_baselines3.common.callbacks import StopTrainingOnNoModelImprovement

   callback = StopTrainingOnNoModelImprovement(
       max_no_improvement_evals=5,
       min_evals=10,
       verbose=1
   )
   ```

## æ•…éšœæ’é™¤

### é—®é¢˜1: ImportError: No module named 'stable_baselines3'

**è§£å†³æ–¹æ¡ˆ:**
```bash
pip install stable-baselines3[extra]
```

### é—®é¢˜2: No data found for symbol XXX

**è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¡®è®¤Tushare Tokené…ç½®æ­£ç¡®
3. éªŒè¯æ—¥æœŸèŒƒå›´æœ‰æ•ˆï¼ˆäº¤æ˜“æ—¥ï¼‰
4. å°è¯•ä½¿ç”¨å…¶ä»–è‚¡ç¥¨ä»£ç 

### é—®é¢˜3: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ:**
```bash
# ä½¿ç”¨CPUè®­ç»ƒ
export CUDA_VISIBLE_DEVICES=""

# æˆ–å‡å°‘æ‰¹æ¬¡å¤§å°
batch_size=32  # ä»64é™åˆ°32
```

### é—®é¢˜4: Training is very slow

**è§£å†³æ–¹æ¡ˆ:**
1. å‡å°‘è®­ç»ƒæ­¥æ•°ï¼ˆæµ‹è¯•æ—¶ï¼‰
2. ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
3. å‡å°‘è‚¡ç¥¨æ•°é‡
4. å‡å°‘æ•°æ®ç‚¹æ•°é‡

### é—®é¢˜5: Model performance is poor (è´Ÿæ”¶ç›Š)

**è§£å†³æ–¹æ¡ˆ:**
1. å¢åŠ è®­ç»ƒæ­¥æ•°ï¼ˆè‡³å°‘100,000æ­¥ï¼‰
2. è°ƒæ•´å¥–åŠ±å‡½æ•°æƒé‡
3. æ£€æŸ¥æ•°æ®è´¨é‡
4. å°è¯•ä¸åŒçš„è¶…å‚æ•°ç»„åˆ

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰è‚¡ç¥¨åˆ—è¡¨

```python
# åˆ›å»ºè®­ç»ƒå™¨æ—¶æŒ‡å®šè‚¡ç¥¨
trainer = RLTrainer(
    symbols=["600519", "000858", "600036"],  # ä»…3åª
    start_date="2025-01-01",
    end_date="2025-10-31"
)
```

### åˆ†é˜¶æ®µè®­ç»ƒ

```python
# ç¬¬ä¸€é˜¶æ®µ: å¿«é€Ÿè®­ç»ƒ
model1 = trainer.train(total_timesteps=50000)

# ç¬¬äºŒé˜¶æ®µ: ç²¾ç»†è°ƒä¼˜ï¼ˆç»§ç»­è®­ç»ƒï¼‰
model2 = PPO.load("models/ppo_trading_agent.zip")
model2.set_env(vec_env)
model2.learn(total_timesteps=50000)
model2.save("models/ppo_trading_agent_v2.zip")
```

### å¤šç­–ç•¥å¯¹æ¯”

```python
# è®­ç»ƒå¤šä¸ªæ¨¡å‹
for lr in [0.0001, 0.0003, 0.001]:
    trainer = RLTrainer(model_save_path=f"models/ppo_lr_{lr}.zip")
    trainer.train(learning_rate=lr)
```

## å‚è€ƒèµ„æ–™

- [Stable-Baselines3 Documentation](https://stable-baselines3.readthedocs.io/)
- [PPO Algorithm Paper](https://arxiv.org/abs/1707.06347)
- [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/)
- [RL Trading Tutorial](https://github.com/AI4Finance-Foundation/FinRL)

## ä¸‹ä¸€æ­¥

1. âœ… è¿è¡Œå¿«é€Ÿæµ‹è¯•ç¡®è®¤ç¯å¢ƒæ­£å¸¸
2. âœ… è¿è¡Œå®Œæ•´è®­ç»ƒè·å¾—ç”Ÿäº§æ¨¡å‹
3. âœ… åœ¨å›æµ‹ç³»ç»Ÿä¸­æµ‹è¯•æ¨¡å‹æ€§èƒ½
4. ğŸ”„ æ ¹æ®å›æµ‹ç»“æœè°ƒä¼˜æ¨¡å‹å‚æ•°
5. ğŸ”„ æŒç»­è¿­ä»£æ”¹è¿›

---

**æœ€åæ›´æ–°**: 2025-01-XX
**ä½œè€…**: Claude Code
**é¡¹ç›®**: HiddenGem Trading System
